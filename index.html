<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Cross Domain Perturbations</title>
        <meta property="og:title" content="Cross Domain Perturbations" />
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">Cross Domain Transferability of Adversarial Perturbations</span>
    </center>

    <br><br>
      <table align=center width=900px>
       <tr>
        <td align=center width=300px>
        <center>
        <span style="font-size:20px"><a href="https://scholar.google.ch/citations?user=tM9xKA8AAAAJ&hl=en/">Muzammal Naseer<sup>1</sup></a></span>
        </center>
        </td>
        <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=M59O9lkAAAAJ&hl=en/">Salman Khan<sup>2</sup> <sup>1</sup></a></span>
        </center>
        </td>

        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=ZgERfFwAAAAJ&hl=en/">Haris Khan<sup>2</sup></a></span>
        </center>
        </td>

        <td align=center width=300px>
        <center>
        <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=zvaeYnUAAAAJ&hl=en">Fahad Shahbaz Khan
<sup>2</sup></a></span>
        </center>
        </td>
           
         <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=VpB8NZ8AAAAJ&hl=en">Fatih Porikli
<sup>1</sup></a></span>
        </center>
        </td>
      
     </tr>
    </table>

    <br>
    <table align=center width=700px>
       <tr>
        <td align=center width=600px>
        <center>
          <span style="font-size:20px"><sup>1</sup>Australian National University</span>
        </center>
        </td>
         <td align=center width=600px>
        <center>
          <span style="font-size:20px"><sup>2</sup>Inception Institute of Artificial Intelligence</span>
        </center>
        </td>
     </tr>
    </table>
      
       <table align=center width=650px>
	  			  <tr>
	  	       
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/Muzammal-Naseer/Cross-domain-perturbations'> [GitHub]</a></span>
		  		  		</center>
		  		  	  </td>

	  	
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://arxiv.org/abs/1905.11736'> [Paper]</a></span>
		  		  		</center>
		  		  	  </td>

		  		  	 </tr>
	  			  <tr>
			  </table>
      
      
    <table align=center width=700px>
     <tr>
    <td align=center width=100px>
    <center>
    <span style="font-size:20px"></span>
    </center>
    </td>
   </tr>
  </table>

            <br>
            <table align=center width=900px>
                <tr>
                    <td width=400px>
                      <center>
                          <a href="./resources/images/teaser.png"><img src = "./resources/images/Teaser.png" height="400px"></img></href></a><br>
                    </center>
                    </td>
                </tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:14px"><i> <span style="font-weight:bold">Transferable Generative Adversarial Perturbation: We demonstrate that common adversaries exist across different image domains and introduce a highly transferable attack approach that carefully crafts adversarial patterns to fool classifiers trained on totally different domains. Our generative scheme learns to reconstruct adversaries on paintings or comics (\emph{left}) that can successfully fool natural image classifiers with high fooling rates at the inference time (\emph{right}).
                      </center>
                    </td>
                </tr>
            </table>

            <br>
           Adversarial examples reveal the blind spots of deep neural networks (DNNs) and represent a major concern for security-critical applications. The transferability of adversarial examples makes real-world attacks possible in black-box settings, where the attacker is forbidden to access the internal parameters of the model. The underlying assumption in most adversary generation methods, whether learning an instance-specific or an instance-agnostic perturbation, is the direct or indirect reliance on the original domain-specific data distribution. In this work, for the first time, we demonstrate the existence of domain-invariant adversaries, thereby showing common adversarial space among different datasets and models. To this end, we propose a framework capable of launching highly transferable attacks that crafts adversarial patterns to mislead networks trained on wholly different domains. For instance, an adversarial function learned on Paintings, Cartoons or Medical images can successfully perturb ImageNet samples to fool the classifier, with success rates as high as $\sim$99\% ($\ell_{\infty} \le 10$). The core of our proposed adversarial function is a generative network that is trained using a relativistic supervisory signal that enables domain-invariant perturbations. Our approach sets the new state-of-the-art for fooling rates, both under the white-box and black-box scenarios. Furthermore, despite being an instance-agnostic perturbation function, our attack outperforms the conventionally much stronger instance-specific attack methods.
           <br><br>
          <hr>
         <!-- <table align=center width=550px> -->
            <table align=center width=650>
             <center><h1>Paper</h1></center>
                <tr>
                    <!--<td width=300px align=left>-->
                    <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
                  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
                  <td><a href="https://arxiv.org/pdf/1905.11736.pdf"><img style="height:180px" src="./resources/images/paper.png"/></a></td>
                  <td><span style="font-size:14pt">Naseer, Salmna, Haris, Fahd, fatih.<br><br>
                          Cross-Domain Transferability of Adversarial Perturbations.<br><br>
                 <br>
                  <!-- [hosted on <a href="#">arXiv</a>]</a> -->
                    </td>
              </tr>
            </table>
          <br>

          <table align=center width=180px>
              <tr>
                  <td><span style="font-size:14pt"><center>
                      <a href="http://www.cs.cmu.edu/~nileshk/papers/3drelnet.pdf">[pdf]</a>
                    </center></td>

                  <td><span style="font-size:14pt"><center>
                      <a href="./resources/images/bibtex.txt">[Bibtex]</a>
                    </center></td>
              </tr>
            </table>
              <br>

                <hr>

         <center><h1>Code</h1></center>
            <table align=center width=1000px>
                <tr>
                        <center>
                          <a href='https://github.com/nileshkulkarni/relative3d'><img class="round" style="height:250" src="./resources/images/overview.png"/></a>
                        </center>
              </tr>
          </table>

            <table align=center width=800px>
              <tr><center> <br>
                <span style="font-size:28px">&nbsp;<a href='https://github.com/nileshkulkarni/relative3d'>[GitHub]</a>

                <span style="font-size:28px"></a></span>
              <br>
              </center></tr>
          </table>
            <br>
          <hr>

        <!--   <center><h1>Results</h1></center>
          <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <a href="./resources/images/vis_comparison.png"><img src = "./resources/images/vis_comparison.png" height="350px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Qualitative comparison.</span> A visualization of the proposed (Factored) representation in comparison to (Voxels) a single voxel grid and (Depth) a depthmap. For each input image shown on the left, we show the various inferred representations from two views each: a) camera view (left), and b) a novel view (right).</i>
                  </center>
                  </td>
              </tr>
          </table>
          <br>
          <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <a href="./resources/images/eval_comparison.png"><img src = "./resources/images/eval_comparison.png" height="170px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Quantitative comparison.</span> Analysis of the ability of various representations to capture different aspects of the whole scene. We compare our proposed factored representation against voxel or depth-based alternatives and evaluate their ability to capture the following aspects of the 3D scene (from left to right): a) Visible depth, b) Volumetric occupancy, c) Individual objects, d) Visible depth for scene surfaces (floor, walls etc.), and e) Amodal depth for scene surfaces.</i>
                  </center>
                  </td>
              </tr>
          </table>
           <hr> -->

            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                <!-- This work was supported in part by Intel/NSF VEC award IIS-1539099, NSF Award IIS-1212798, and the Google Fellowship to SG. We gratefully acknowledge NVIDIA corporation for the donation of Tesla GPUs used for this research. -->
                This work was done at Inception Institute of Artificial Intelligence. This webpage template was borrowed from <a href="https://richzhang.github.io/colorization/">Richard Zhang</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
